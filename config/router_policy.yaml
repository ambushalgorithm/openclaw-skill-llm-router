# Router Policy Configuration
#
# Controls which models are available for routing and task-specific restrictions.
# This file is read at router initialization - restart to apply changes.
#
# Structure:
# - disabled_models: List of model IDs to never use (e.g., "ollama/glm-4.6")
# - disabled_providers: List of providers to disable entirely
# - category_policies: Per-category/task restrictions
# - global_limits: Default constraints applied when not overridden

version: "1.0"
last_updated: "2026-02-07"

# ============================================================================
# Globally Disabled Models
# These models exist in the catalog but will never be selected
# ============================================================================
disabled_models:
  # === EXPENSIVE MODELS (keep disabled unless needed) ===
  - anthropic/claude-opus-4
  - openai/gpt-5.2-pro
  - openai/o1

# ============================================================================
# Globally Disabled Providers
# All models from these providers are excluded
# ============================================================================
disabled_providers: []
  # Examples:
  # - openai                  # Uncomment to completely exclude OpenAI

# ============================================================================
# Category/Task-Specific Policies
# Maps legacy category names to routing constraints
# ============================================================================
category_policies:
  # --------------------------------------------------------------------------
  # Heartbeat - Minimal cost, simple queries
  # --------------------------------------------------------------------------
  Heartbeat:
    description: "Simple health checks and minimal queries"
    allowed_tiers: [SIMPLE]           # Never use COMPLEX/REASONING models
    max_cost_per_1k: 0.001            # Under $1/M tokens
    required_capabilities: [chat]     # Absolute minimum
    cost_optimized: true              # Always use cheapest models for heartbeats
    preferred_models:                 # Try these first (in order)
      - ollama/ministral-3:14b-cloud
      - ollama/gemini-3-flash-preview:cloud
      - anthropic/claude-haiku-4-5
    exclude_models: []                # Additional exclusions beyond global
    exclude_quota_limited: true       # Never fallback to OpenAI

  # --------------------------------------------------------------------------
  # Primary LLM - General chat, cheap and fast
  # --------------------------------------------------------------------------
  Primary_LLM:
    description: "General conversation, simple Q&A"
    allowed_tiers: [SIMPLE, MEDIUM]   # Can use slightly smarter models
    max_cost_per_1k: 0.003
    required_capabilities: [chat]
    exclude_models:
      - anthropic/claude-opus-4       # Too expensive for simple chat
      - anthropic/claude-opus-4-5
    exclude_quota_limited: true

  # --------------------------------------------------------------------------
  # Brain - Balanced reasoning and chat
  # --------------------------------------------------------------------------
  Brain:
    description: "General reasoning, analysis, explanations"
    allowed_tiers: [MEDIUM, COMPLEX]  # Prefer balanced to powerful
    max_cost_per_1k: 0.010
    required_capabilities: [chat, reasoning]
    preferred_models:
      - ollama/kimi-k2.5:cloud        # Best overall (vision, reasoning, agentic)
      - ollama/deepseek-v3.1:671b-cloud # Reasoning + thinking mode
      - ollama/minimax-m2:cloud       # Efficient fallback
      - ollama/minimax-m2.1:cloud     # Extended context version
      - anthropic/claude-sonnet-4-5
    exclude_models:
      - ollama/ministral-3:14b-cloud  # No reasoning
    exclude_quota_limited: true

  # --------------------------------------------------------------------------
  # Coding - Software development tasks
  # --------------------------------------------------------------------------
  Coding:
    description: "Code generation, debugging, architecture"
    allowed_tiers: [MEDIUM, COMPLEX, REASONING]  # All tiers okay
    max_cost_per_1k: 0.020            # Up to $20/M for good code
    required_capabilities: [code]     # Must have code capability
    preferred_tags: [code, agentic]   # Prefer agentic coding models
    preferred_models:
      - ollama/kimi-k2.5:cloud        # Best agentic + reasoning
      - ollama/deepseek-v3.2:cloud    # Fastest, cheapest pure coding
      - ollama/qwen3-coder-next:cloud # Agentic coding (updated daily)
      - ollama/devstral-2:123b-cloud  # Software engineering agent
      - ollama/rnj-1:8b-cloud         # 8B efficient code/STEM
      - ollama/minimax-m2:cloud       # Efficient multitask
      - ollama/minimax-m2.1:cloud     # Extended context version
      - anthropic/claude-sonnet-4-5   # Reliable fallback
    exclude_models:
      - ollama/ministral-3:14b-cloud  # Weak coding
      - anthropic/claude-haiku-4-5    # No code capability
    exclude_quota_limited: true

  # --------------------------------------------------------------------------
  # Web Search - Research tasks
  # --------------------------------------------------------------------------
  Web_Search:
    description: "Web research, data gathering"
    allowed_tiers: [MEDIUM, COMPLEX]
    max_cost_per_1k: 0.010            # Keep research cheap
    required_capabilities: [chat, reasoning]
    # Exclude expensive models even if they match capabilities
    exclude_models:
      - anthropic/claude-opus-4       # $75/M is too much for research
      - anthropic/claude-opus-4-5     # $25/M still expensive
      - openai/gpt-5.2-pro            # $168/M
      - openai/o1                     # $60/M
    exclude_quota_limited: true

  # --------------------------------------------------------------------------
  # Writing Content - Creative writing
  # --------------------------------------------------------------------------
  Writing_Content:
    description: "Creative writing, editing, style"
    allowed_tiers: [SIMPLE, MEDIUM, COMPLEX]
    max_cost_per_1k: 0.005
    required_capabilities: [chat]
    preferred_models:
      - ollama/kimi-k2.5:cloud        # Good general purpose
      - ollama/deepseek-v3.2:cloud    # Cheap and capable
      - anthropic/claude-sonnet-4-5
    exclude_models: []
    exclude_quota_limited: true

  # --------------------------------------------------------------------------
  # Image Understanding - Vision tasks
  # --------------------------------------------------------------------------
  Image_Understanding:
    description: "Vision analysis, image descriptions"
    allowed_tiers: [COMPLEX]          # Vision needs more compute
    max_cost_per_1k: 0.010
    required_capabilities: [vision]   # MUST have vision
    preferred_models:                 # Specific ranking for vision
      - ollama/kimi-k2.5:cloud        # Best vision + reasoning
      - anthropic/claude-sonnet-4-5   # Reliable vision fallback
    exclude_models:
      - anthropic/claude-opus-4       # Too expensive
    exclude_quota_limited: true

  # --------------------------------------------------------------------------
  # Voice - Audio/Transcription (not currently used)
  # --------------------------------------------------------------------------
  Voice:
    description: "Voice tasks (currently unused)"
    allowed_tiers: [MEDIUM]
    max_cost_per_1k: 0.010
    required_capabilities: [chat]
    # No specific models - uses tier defaults
    exclude_quota_limited: true

# ============================================================================
# Global Defaults (when no category matches or category doesn't specify)
# ============================================================================
global_limits:
  max_cost_per_1k: 0.050              # Absolute ceiling: $50/M tokens
  exclude_quota_limited: true         # Default: don't use OpenAI

  # When classifier can't decide (ambiguous), default to this tier
  default_tier_on_ambiguous: MEDIUM

  # Cost optimization: Prefer cheaper models for MEDIUM/SIMPLE tiers
  # When true: MiniMax/DeepSeek prioritized over Kimi for lower tiers
  # When false: Kimi prioritized (best quality regardless of cost)
  cost_optimized: true                # Enabled: prefer MiniMax/DeepSeek when appropriate

  # Cloud-only mode: Only use Ollama Cloud tagged models
  # When true: Excludes any models not explicitly marked "cloud" in the catalog
  # Ensures you're only routing to Ollama Cloud Pro available models
  cloud_only: true                    # Filter to Ollama Cloud models only

  # When no models match constraints, relax these in order:
  fallback_relaxation:
    - try_without_quota_exclusion     # Try OpenAI last resort
    - try_next_tier_up                # If SIMPLE failed, try MEDIUM
    - double_cost_ceiling             # 2x budget before failing

# ============================================================================
# Provider Priority (when multiple models match equally)
# ============================================================================
provider_priority:
  - ollama          # Primary - always try first
  - anthropic       # Secondary - reliable fallback
  - openai          # Tertiary - only if quota allows
